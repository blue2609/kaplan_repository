{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break up Excel File to Multiple CSV Flat Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to execute this section of codes. Just trying out some stuff, how to break up excel workbook with multiple worksheets into distinct CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelFileName = 'Financial_Data'\n",
    "# PATH_TO_POWERSHELL_EXECUTABLE = r\"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\"\n",
    "# PATH_TO_POWERSHELL_SCRIPT = r\"C:\\Users\\stanley.setiawan\\Documents\\Lessons\\PowerShell\\ConvertExcelToCSV\\convertToCSV.ps1\"\n",
    "# PATH_TO_POWERSHELL_EXECUTABLE = r\"powershell\"\n",
    "# PATH_TO_POWERSHELL_SCRIPT = r\"./convertToCSV.ps1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# subprocess.run(['powershell.exe','convertToCSV.ps1',excelFileName])    \n",
    "# subprocess.run([PATH_TO_POWERSHELL_EXECUTABLE,PATH_TO_POWERSHELL_SCRIPT,excelFileName])    \n",
    "subprocess.run([r'powershell','./convertToCSV.ps1',excelFileName])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import re\n",
    "import pyodbc\n",
    "from collections import namedtuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'Column_1':['Stanley','Leonhard','Setiawan',None],\n",
    "                        'Column_2':['22','This is it','random',None],\n",
    "                        'Column_3':['11/22/2017','12/20/2018','09/05/2020',None],\n",
    "                        'Column_4':['10/27/2015','12/15/2016','10/31/2015',None]})\n",
    "\n",
    "test_df['Column_5'] = pd.Series(['Jan','Feb','Mar',None])\n",
    "test_df['Column_6'] = pd.Series(['January','February','March',None])\n",
    "test_df['Column_7'] = [22,None,'',None]\n",
    "test_df['Column_8'] = [3.5,0.05,999.4,None]\n",
    "test_df['Column_9'] = ['15:00','03:00','09:00',None]\n",
    "test_df['Column_10'] = ['   ',' stanley this ',' ',\"\\n \\n \\t some'String\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column_1</th>\n",
       "      <th>Column_2</th>\n",
       "      <th>Column_3</th>\n",
       "      <th>Column_4</th>\n",
       "      <th>Column_5</th>\n",
       "      <th>Column_6</th>\n",
       "      <th>Column_7</th>\n",
       "      <th>Column_8</th>\n",
       "      <th>Column_9</th>\n",
       "      <th>Column_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stanley</td>\n",
       "      <td>22</td>\n",
       "      <td>11/22/2017</td>\n",
       "      <td>10/27/2015</td>\n",
       "      <td>Jan</td>\n",
       "      <td>January</td>\n",
       "      <td>22</td>\n",
       "      <td>3.50</td>\n",
       "      <td>15:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leonhard</td>\n",
       "      <td>This is it</td>\n",
       "      <td>12/20/2018</td>\n",
       "      <td>12/15/2016</td>\n",
       "      <td>Feb</td>\n",
       "      <td>February</td>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>03:00</td>\n",
       "      <td>stanley this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Setiawan</td>\n",
       "      <td>random</td>\n",
       "      <td>09/05/2020</td>\n",
       "      <td>10/31/2015</td>\n",
       "      <td>Mar</td>\n",
       "      <td>March</td>\n",
       "      <td></td>\n",
       "      <td>999.40</td>\n",
       "      <td>09:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n \\n \\t some'String</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column_1    Column_2    Column_3    Column_4 Column_5  Column_6 Column_7  \\\n",
       "0   Stanley          22  11/22/2017  10/27/2015      Jan   January       22   \n",
       "1  Leonhard  This is it  12/20/2018  12/15/2016      Feb  February     None   \n",
       "2  Setiawan      random  09/05/2020  10/31/2015      Mar     March            \n",
       "3      None        None        None        None     None      None     None   \n",
       "\n",
       "   Column_8 Column_9             Column_10  \n",
       "0      3.50    15:00                        \n",
       "1      0.05    03:00         stanley this   \n",
       "2    999.40    09:00                        \n",
       "3       NaN     None  \\n \\n \\t some'String  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows which contain em\n",
    "# Adj_Close_df.dropna(how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Function to find out data type of a dataframe column (Pandas Series Object) \n",
    "# ============================================================================\n",
    "\n",
    "def findDataType(dataFrameColumn):\n",
    "    try:\n",
    "        column = pd.to_numeric(dataFrameColumn)\n",
    "        dataType=column.dtype.name\n",
    "    except:\n",
    "        try:\n",
    "            column = pd.to_datetime(dataFrameColumn)\n",
    "        except:\n",
    "            column = dataFrameColumn.astype('string')\n",
    "            dataType = column.dtype.name\n",
    "        else:\n",
    "            if (column.dt.floor('d') == column).all():\n",
    "                dataType = 'date'\n",
    "            elif (column.dt.date == pd.Timestamp('now')).all():\n",
    "                dataType = 'time'\n",
    "            else:\n",
    "                dataType=column.dtype.name\n",
    "    finally:\n",
    "        return dataType\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================================================================\n",
    "# Function to convert the dataframe data types to SQL Data Types \n",
    "# ====================================================================\n",
    "\n",
    "def getSQLTableStructure(dataframe):\n",
    "    sqlTableStructure = {}\n",
    "    sqlColumn = namedtuple('sqlColumn',[\n",
    "         'sqlDataType',\n",
    "         'noOfNulls',\n",
    "         'allowNull'\n",
    "    ])\n",
    "\n",
    "    dataFrameStructure = getDataframeStructure(dataframe)\n",
    "    for columnName,namedTupleObj in dataFrameStructure.items():\n",
    "\n",
    "        #-----------------------------------------------------\n",
    "        # Parse integer to its corresponding data type in SQL\n",
    "        #-----------------------------------------------------\n",
    "        if 'int' in namedTupleObj.dataType:  \n",
    "\n",
    "            #get the number of bits used \n",
    "            no_of_bits = re.search('\\d+',namedTupleObj.dataType).group()\n",
    "\n",
    "            if no_of_bits == '32':\n",
    "                sqlDataType = 'int'\n",
    "            elif no_of_bits == '64':\n",
    "                sqlDataType = 'bigint'\n",
    "            elif no_of_bits == '16':\n",
    "                sqlDataType = 'smallint'\n",
    "            elif no_of_bits == '8':\n",
    "                sqlDataType = 'tinyint'\n",
    "\n",
    "        elif 'float' in namedTupleObj.dataType:\n",
    "\n",
    "            sqlDataType = 'float'\n",
    "\n",
    "        elif 'date' == namedTupleObj.dataType:\n",
    "\n",
    "            sqlDataType = 'date'\n",
    "\n",
    "        elif 'time' == namedTupleObj.dataType:\n",
    "\n",
    "            sqlDataType = 'time'\n",
    "\n",
    "        elif 'datetime' in namedTupleObj.dataType:\n",
    "\n",
    "            sqlDataType = 'datetime'\n",
    "\n",
    "        elif 'string' == namedTupleObj.dataType:\n",
    "\n",
    "            # get the max number of bytes required for this column\n",
    "            maxByteSize = dataframe[columnName].apply(lambda eachString: len(eachString.encode('UTF-8'))).max()\n",
    "            sqlDataType = f'varchar({maxByteSize})'\n",
    "\n",
    "            # need more functionality here to detect fixed string column\n",
    "\n",
    "        # add a new sqlColumn to sqlTableStructure dictionary\n",
    "        # based on the converted data type\n",
    "        sqlTableStructure[columnName] = sqlColumn(sqlDataType=sqlDataType,\n",
    "                                                  noOfNulls=namedTupleObj.noEmptyCells,\n",
    "                                                  allowNull=namedTupleObj.allowNull)\n",
    "    \n",
    "    return (sqlTableStructure,dataFrameStructure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===========================================================\n",
    "# Get Data type for each column of pandas dataframe\n",
    "# =========================================================\n",
    "\n",
    "def getDataframeStructure(dataframe):\n",
    "    sql_table_structure = {}\n",
    "    sqlColumn = namedtuple('sqlColumn',[\n",
    "        'dataType',\n",
    "        'noEmptyCells',\n",
    "        'allowNull' \n",
    "    ])\n",
    "\n",
    "    for columnName in dataframe.columns:\n",
    "\n",
    "        column = dataframe[columnName]\n",
    "\n",
    "        # Get the row indexes which contain empty value/empty string or None/Null\n",
    "        empty_cells_indexes = column[(column.isna()) | \n",
    "                                     (column == '') |\n",
    "                                     (column.astype(str).str.isspace())].index\n",
    "        \n",
    "        # assign 'NULL' string to dataframe values that is either:\n",
    "        # - a 'None'\n",
    "        # - an empty string ''\n",
    "        # - just a string that contains whitespaces '    '\n",
    "        dataframe[columnName][empty_cells_indexes] = 'NULL'\n",
    "\n",
    "        allowNull = '' if empty_cells_indexes.size > 0 else 'NOT NULL' \n",
    "\n",
    "        # drop the empty_cells_indexes from the column (if there's any)\n",
    "        cleaned_column = column.drop(labels=empty_cells_indexes)\n",
    "\n",
    "        # ----------------------------------------------------- \n",
    "        # make a best guess what the data type of the column is \n",
    "        # ----------------------------------------------------- \n",
    "\n",
    "        sql_table_structure[columnName] = sqlColumn(dataType=findDataType(cleaned_column),\n",
    "                                                    noEmptyCells=empty_cells_indexes.size,\n",
    "                                                    allowNull=allowNull)\n",
    "        \n",
    "    # return a dictionary containing the implied basic SQL Table Structure\n",
    "    return sql_table_structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# Generate the SQL String which will create a table\n",
    "# =========================================================\n",
    "\n",
    "def createTableQueryString(dbName,schema,tableName,sqlTableStructure):\n",
    "    queryString = f'CREATE TABLE {dbName}.{schema}.{tableName}('\n",
    "    \n",
    "    for columnName,sqlColumn in sqlTableStructure.items():\n",
    "        queryString += f'\\n\"{columnName}\" {sqlColumn.sqlDataType} {sqlColumn.allowNull},'\n",
    "    \n",
    "    queryString += ');'\n",
    "    return queryString\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# Generate SQL query to insert values into database talbe\n",
    "# =========================================================\n",
    "\n",
    "def insertValuesQueryString(dbName,schema,tableName,dataframe):\n",
    "    \n",
    "    # get a list of columnNames from dataframe\n",
    "    columnNamesList = ','.join([f'\"{columnName}\"' for columnName in dataframe.columns]) \n",
    "    queryString = f'INSERT INTO {dbName}.{schema}.{tableName} ({columnNamesList}) \\n VALUES \\n' \n",
    "    \n",
    "    for index,*values in dataframe.itertuples():\n",
    "        if index == dataframe.index[-1]:\n",
    "            queryString += '(' + ','.join([\"'\" + str(value).replace(\"'\",\"''\") + \"'\" \n",
    "                                           if str(value) != 'NULL' else 'NULL'\n",
    "                                           for value in values]) + ')'\n",
    "        else:\n",
    "            queryString += '(' + ','.join([\"'\" + str(value).replace(\"'\",\"''\") + \"'\" \n",
    "                                           if str(value) != 'NULL' else 'NULL' \n",
    "                                           for value in values]) + '),\\n'\n",
    "    return queryString\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "indexes = np.where((test_df.isna()) |  \n",
    "                    (test_df == '') |\n",
    "                    (test_df.apply(lambda row: row.str.isspace(), axis = 1)))\n",
    "\n",
    "for rowNum,colNum in zip(indexes[0],indexes[1]):\n",
    "    test_df.iloc[rowNum,colNum] = 'NULL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import other dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is optional, it's just to import other dataframes if we want to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('Boston_Crimes.csv',encoding='latin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Microsoft SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=KA-PF14P8C2\\SQLEXPRESS;'\n",
    "                      'Database=MBAN;'\n",
    "                      'Trusted_Connection=yes;')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "createTableString = createTableQueryString('MBAN','dbo','test',getSQLTableStructure(test_df)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertValueString = insertValuesQueryString('MBAN','dbo','test',test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE MBAN.dbo.test(\n",
      "\"Column_1\" varchar(8) ,\n",
      "\"Column_2\" varchar(10) ,\n",
      "\"Column_3\" date ,\n",
      "\"Column_4\" date ,\n",
      "\"Column_5\" varchar(4) ,\n",
      "\"Column_6\" varchar(8) ,\n",
      "\"Column_7\" bigint ,\n",
      "\"Column_8\" float ,\n",
      "\"Column_9\" time ,\n",
      "\"Column_10\" varchar(17) ,);\n"
     ]
    }
   ],
   "source": [
    "print(createTableString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO MBAN.dbo.test (\"Column_1\",\"Column_2\",\"Column_3\",\"Column_4\",\"Column_5\",\"Column_6\",\"Column_7\",\"Column_8\",\"Column_9\",\"Column_10\") \n",
      " VALUES \n",
      "('Stanley','22','11/22/2017','10/27/2015','Jan','January','22','3.5','15:00',NULL),\n",
      "('Leonhard','This is it','12/20/2018','12/15/2016','Feb','February',NULL,'0.05','03:00',' stanley this '),\n",
      "('Setiawan','random','09/05/2020','10/31/2015','Mar','March',NULL,'999.4','09:00',NULL),\n",
      "(NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL,'\n",
      " \n",
      " \t some''String')\n"
     ]
    }
   ],
   "source": [
    "print(insertValueString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x25ca47e5db0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(createTableString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x25ca47e5db0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(insertValueString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('file.txt','w') as textFile:\n",
    "#     textFile.write(insertValueString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.0.0-unsupported'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyodbc.version"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
